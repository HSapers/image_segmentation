{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D: Set shape of NPZ files for optimum annotator ease\n",
    "Crop array into overlapping x and y crops\n",
    "Split an array up into smaller crops that overlap one another\n",
    "\n",
    "Check crop size\n",
    "First set parameters to check that crop size and overlap are appropriate\n",
    "\n",
    "load up huge array, pick the xy overlapping and processes these (not written to disk) take these re-shaped array and apply a slicing step to each apply the xy crops and write these files to disk. Makes a log of the settings used so that reconstruction is possible. \n",
    "\n",
    "* note that caliban toolbox must first be installed to your python env*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import glob\n",
    "import os\n",
    "import path\n",
    "import ntpath\n",
    "import stat\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Image processing tools\n",
    "import mrcfile\n",
    "\n",
    "import skimage\n",
    "import skimage.io\n",
    "from imageio import imread, volread, imwrite, volwrite\n",
    "from ipywidgets import fixed, interactive\n",
    "\n",
    "\n",
    "#import caliban_toolbox.pre_annotation.data_loader\n",
    "#from caliban_toolbox import reshape_data\n",
    "#from caliban_toolbox.figure_eight_functions import create_figure_eight_job, download_figure_eight_output\n",
    "#from caliban_toolbox.utils import widget_utils, plot_utils, data_utils, io_utils\n",
    "\n",
    "from bokeh.palettes import Viridis, Greys\n",
    "from bokeh.io import export_png\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage import filters, img_as_uint\n",
    "perm_mod = stat.S_IRWXO | stat.S_IRWXU | stat.S_IRWXG\n",
    "\n",
    "import bebi103\n",
    "\n",
    "import bokeh\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "\n",
    "import colorcet\n",
    "\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of crop\n",
    "crop_size = (480, 480)\n",
    "\n",
    "# fraction of crop that will overlap with adjacent crops\n",
    "overlap_frac = 0.1\n",
    "\n",
    "# index of channel in npz to visualize\n",
    "channels_idx = 1\n",
    "\n",
    "# where crops will get saved\n",
    "save_dir = \"/example_data/timelapse/HeLa_by_image/crop_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we next add in dimensions of size 1 for any missing dims in input array to bring it up to standard size\n",
    "X_expanded = data_utils.pad_xr_dims(input_xr=channel_xr)\n",
    "y_expanded = data_utils.pad_xr_dims(input_xr=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll test these parameters to see how the crops look\n",
    "cropped_stack_test, cropped_y_test, log_data_test = reshape_data.crop_multichannel_data(X_data=X_expanded, \n",
    "                                                                                        y_data=y_expanded, \n",
    "                                                                                        crop_size=crop_size,\n",
    "                                                                                        overlap_frac=overlap_frac,\n",
    "                                                                                        test_parameters=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll add in line overlays for easier visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract information about test crop dimensions\n",
    "row_starts, row_ends  = log_data_test[\"row_starts\"], log_data_test[\"row_ends\"]\n",
    "col_starts, col_ends = log_data_test[\"col_starts\"], log_data_test[\"col_ends\"]\n",
    "\n",
    "# get a single crop from the stack of cropped images\n",
    "example_crop = cropped_stack_test[0, 0, 3, 0, :, :, channels_idx]\n",
    "\n",
    "# load the first image from the xarray stack, which is the one that the crops were generated from\n",
    "example_img = copy.deepcopy(X_expanded[0, 0, 0, 0, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_img_overlay = plot_utils.overlay_grid_lines(overlay_img=example_img[:, :, channels_idx], \n",
    "                                                    row_starts=row_starts, row_ends=row_ends, col_starts=col_starts, \n",
    "                                                    col_ends=col_ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(example_img_overlay[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an overlay of a single crop showing where borders are located\n",
    "img_crop_overlay = plot_utils.overlay_crop_overlap(img_crop=example_crop.values, row_starts=row_starts,\n",
    "                                                   row_ends=row_ends, col_starts=col_starts, col_ends=col_ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(img_crop_overlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once the parameters above look good, we'll crop the images\n",
    "X_cropped, y_cropped, log_data = reshape_data.crop_multichannel_data(X_data=X_expanded, y_data=y_expanded, \n",
    "                                                                     crop_size=crop_size, \n",
    "                                                                     overlap_frac=overlap_frac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we need to crop in Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write cropped subvolumes and log to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cropped data into npz files for upload \n",
    "io_utils.save_npzs_for_caliban(X_data=X_cropped, y_data=y_cropped, original_data=channel_data, save_dir=save_dir,\n",
    "                                   log_data=log_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
